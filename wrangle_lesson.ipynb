{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire and Prep - Wrangle\n",
    "\n",
    "What is special about preparing data for linear regression?\n",
    "\n",
    "- Linear Assumption: Possibly transform data to make the relationship linear (e.g. log transform for an exponential relationship).\n",
    "- Remove Noise/Outliers: Most important for the output variable and you want to remove outliers in the output variable (y) if possible.\n",
    "- Remove Collinearity. Linear regression will over-fit your data when you have highly correlated input variables. Consider calculating pairwise correlations for your input data and removing the most correlated.\n",
    "- Gaussian Distributions. Linear regression will make more reliable predictions if your input and output variables have a Gaussian distribution.\n",
    "- Rescale Inputs: Linear regression will often make more reliable predictions if you rescale input variables using standardization or normalization.\n",
    "\n",
    "In the following lessons, we will walk through the data science pipeline using the following scenario:\n",
    "\n",
    "I'm a university teacher, and I want to know when to worry about a student's progress.  I want to be able to work with any students who are at high risk of failing the class, so that I can try to prevent that from happening.  I have the grades of the three exams and the final grade from last semester's class.  I'm hoping I can build a prediction model that will be able to use these exams to predict the final grade within 5 points average per student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire the Data\n",
    "\n",
    "Let's use pandas to read our csv into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv file into pandas DataFrame.\n",
    "file = \"https://gist.githubusercontent.com/ryanorsinger/14c8f919920e111f53c6d2c3a3af7e70/raw/07f6e8004fa171638d6d599cfbf0513f6f60b9e8/student_grades.csv\"\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample and Summarize\n",
    "\n",
    "Let's take a look at the DataFrame we brought in and document our initial findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 104 rows and 5 columns coming in.\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display readable summary statistics for numeric columns. Why isn't exam3 showing up?\n",
    "\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running .info() shows us that the exam3 column is not a numeric data type; it's an object.\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acquire and Summarize Takeaways\n",
    "\n",
    "- Need to change the datatype of exam3\n",
    "- Drop the studentid\n",
    "- Why is exam1 reading in as a float\n",
    "- Why does exam1 have 1 fewer value than everything else\n",
    "- Why is exam3 an object dtype?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Null Values\n",
    "\n",
    "Let's check out some other ways to find Null values when you are dealing with a larger dataframe, especially one with more attributes and more missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- np.nan values have a float data type. When a column you expect to have an integer data type reads in as a float, this may be signaling that there is one or more Null values present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.isnull().sum()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the total number of Null values in each column of our DataFrame.\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`.isna()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can visualize the row(s) in exam1 containing at least one np.nan\n",
    "df[df.exam1.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.isnull().any()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any Null values in each column of our DataFrame.\n",
    "\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the names for any columns in our DataFrame with any Null values.\n",
    "\n",
    "df.columns[df.isnull().any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Odd Values\n",
    "\n",
    "Let's find the odd value in `exam3` that is causing this numeric column to be coerced into an object data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the values and their frequencies from exam3 column.\n",
    "\n",
    "df['exam3'].value_counts(dropna=False, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace a whitespace sequence or empty with a NaN value and reassign this manipulation to df.\n",
    "\n",
    "df = df.replace(r'^\\s*$', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that our empty string has been replaced by a null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now .info() shows us that exam3 has a Null value instead of a whitespace disguised as a non-null value.\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.exam3.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Null Values\n",
    "\n",
    "Let's drop observations that have any Null values; in this case, we have so few that we can simply drop rows instead of imputing values to save observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows with any Null values, assign to df, and verify.\n",
    "\n",
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Data Types\n",
    "\n",
    "Let's convert any data types we need to at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change all column data tyes to int64, reassign to df, and verify.\n",
    "\n",
    "df = df.astype('int')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to fill your missing values with a value instead of dropping the rows. One way to do this is to apply the `.fillna()` method to your dataframe. \n",
    "```python\n",
    "# Default arguments for value and method parameters.\n",
    "\n",
    "df.fillna(value=None, method=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running `.describe()`, we should now see `exam3` listed since we have converted it to a numeric type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Distributions\n",
    "\n",
    "We can plot histograms and/or boxplots to see the distributions of single variables and check for skewness, outliers, and unit scales. *Note, we don't have to split our data before exploring single variables. We DO have to split our data before performing bi- and multi-variate exploration.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `sns.displot()`\n",
    "\n",
    "We can use Seaborn's `displot` to display the binned values from a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default is bins=8.\n",
    "\n",
    "sns.displot(x='final_grade', data=df)\n",
    "\n",
    "plt.title('final_grade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `plt.subplot()` & `.hist()`\n",
    "\n",
    "Here we'll loop through each of the numeric columns of interest and show the distribution of each on a separate subplot. We can use **`enumerate()`** to simplify our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 3))\n",
    "\n",
    "# List of columns\n",
    "cols = ['exam1', 'exam2', 'exam3', 'final_grade']\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "    \n",
    "    # i starts at 0, but plot nos should start at 1\n",
    "    plot_number = i + 1 \n",
    "    \n",
    "    # Create subplot.\n",
    "    plt.subplot(1,4, plot_number)\n",
    "    \n",
    "    # Title with column name.\n",
    "    plt.title(col)\n",
    "    \n",
    "    # Display histogram for column.\n",
    "    df[col].hist(bins=5, edgecolor='black')\n",
    "    \n",
    "    # Hide gridlines.\n",
    "    plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mini-Lesson**: What is **`enumerate()`** doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can loop through an array:\n",
    "for col in cols:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can loop through an array while keeping a running count as we do so:\n",
    "i = 0\n",
    "\n",
    "for col in cols:\n",
    "    print(i, col)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enumerate() does the same as above in fewer lines of code:\n",
    "for i, col in enumerate(cols):\n",
    "    print(i, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `sns.boxplot()`\n",
    "\n",
    "Seaborn's `.boxplot` will default to plotting *all* the numeric variables if we don't specify specific x and y values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't want to plot the `student_id` column.\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "# Create boxplots for all but student_id.\n",
    "sns.boxplot(data=df.drop(columns=['student_id']))\n",
    "plt.title('')\n",
    "plt.ylabel('Grade')\n",
    "plt.xlabel('Assessment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution Takeaways?\n",
    "\n",
    "- No obvious outliers\n",
    "- Exam2 not as normally distributed as the others\n",
    "- Exam1 has widest range of values\n",
    "- Exam3 has higher median than others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, k, col_list):\n",
    "    ''' remove outliers from a list of columns in a dataframe \n",
    "        and return that dataframe\n",
    "    '''\n",
    "    \n",
    "    for col in col_list:\n",
    "\n",
    "        q1, q3 = df[col].quantile([.25, .75])  # get quartiles\n",
    "        \n",
    "        iqr = q3 - q1   # calculate interquartile range\n",
    "        \n",
    "        upper_bound = q3 + k * iqr   # get upper bound\n",
    "        lower_bound = q1 - k * iqr   # get lower bound\n",
    "\n",
    "        # return dataframe without outliers\n",
    "        \n",
    "        df = df[(df[col] > lower_bound) & (df[col] < upper_bound)]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_outliers(df, 1.5, ['exam1', 'exam2', 'exam3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Function\n",
    "\n",
    "We finalize these data wrangling steps (acquire and prepare) by writing a function that will reproduce the DataFrame with the necessary changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_grades(file=file):\n",
    "    '''\n",
    "    Read student_grades csv file into a pandas DataFrame,\n",
    "    drop student_id column, replace whitespaces with NaN values,\n",
    "    drop any rows with Null values, convert all columns to int64,\n",
    "    return cleaned student grades DataFrame.\n",
    "    '''\n",
    "    # Acquire data from csv file.\n",
    "    grades = pd.read_csv(file)\n",
    "    \n",
    "    # Replace white space values with NaN values.\n",
    "    grades = grades.replace(r'^\\s*$', np.nan, regex=True)\n",
    "    \n",
    "    # Drop all rows with NaN values.\n",
    "    df = grades.dropna()\n",
    "    \n",
    "    # Convert all columns to int64 data types.\n",
    "    df = df.astype('int')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test out or wrangle function from above.\n",
    "\n",
    "df = wrangle_grades()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises I\n",
    "\n",
    "Let's review the steps we take at the beginning of each new module.\n",
    "\n",
    "1. Create a new repository named `regression-exercises` in your GitHub; all of your Regression work will be housed here.\n",
    "1. Clone this repository within your local `codeup-data-science` directory.\n",
    "1. Create a `.gitignore` and make sure your list of 'files to ignore' includes your `env.py` file.\n",
    "1. Ceate a `README.md` file that outlines the contents and purpose of your repository.\n",
    "1. Add, commit, and push these two files.\n",
    "1. Now you can add your `env.py` file to this repository to access the Codeup database server.\n",
    "1. For these exercises, you will create `wrangle.ipynb` and `wrangle.py` files to hold necessary functions.\n",
    "1. As always, add, commit, and push your work often.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises II\n",
    "\n",
    "Let's set up an example scenario as perspective for our regression exercises using the Zillow dataset.\n",
    "\n",
    "As a Codeup data science graduate, you want to show off your skills to the Zillow data science team in hopes of getting an interview for a position you saw pop up on LinkedIn. You thought it might look impressive to build an end-to-end project in which you use some of their Kaggle data to predict property values using some of their available features; who knows, you might even do some feature engineering to blow them away. Your goal is to predict the values of single unit properties using the obervations from 2017.\n",
    "\n",
    "In these exercises, you will complete the first step toward the above goal: acquire and prepare the necessary Zillow data from the zillow database in the Codeup database server.\n",
    "\n",
    "1. Acquire `bedroomcnt`, `bathroomcnt`, `calculatedfinishedsquarefeet`, `taxvaluedollarcnt`, `yearbuilt`, `taxamount`, and `fips` from the `zillow` database for all 'Single Family Residential' properties.\n",
    "1. Using your acquired Zillow data, walk through the summarization and cleaning steps in your `wrangle.ipynb` file like we did above. You may handle the missing values however you feel is appropriate and meaninful; remember to document your process and decisions using markdown and code commenting where helpful.\n",
    "1. Store all of the necessary functions to automate your process from acquiring the data to returning a cleaned dataframe witn no missing values in your `wrangle.py` file. Name your final function `wrangle_zillow`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
